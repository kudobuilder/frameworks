# Flink Financial Fraud Demo

This demo follows the outline provided by [DCOS's](https://github.com/dcos/demos/tree/master/flink-k8s/1.11) demo

### Architecture

![Financial transaction processing demo architecture](https://github.com/dcos/demos/raw/master/flink-k8s/1.11/img/kafka-flink-arch.png)

This demo implements a data processing infrastructure with KUDO that is able to spot money laundering. In the context of money laundering, we  want to detect amounts larger than $10.000 transferred between two accounts, even if that amount is split into many small batches.  See also [US](https://www.fincen.gov/history-anti-money-laundering-laws) and [EU](http://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32015L0849) legislation and regulations on this topic for more information.

The architecture follows more or less the [SMACK stack architecture](https://mesosphere.com/blog/smack-stack-new-lamp-stack/):
- Events: Event are being generated by a small [Golang generator](https://github.com/dcos/demos/blob/master/flink/1.11/generator/generator.go). The events are in the form 'Sunday, 23-Jul-17 01:06:47 UTC;66;26;7810', where the first field '23-Jul-17 01:06:47 UTC' represents the (increasing) timestamp of transactions; the second field '66' represent the sender account; the third field the receiver account; and the fourth field represent the dollar amount transferred during that transaction.
- Ingestion: The generated events are being ingested and buffered by a Kafka queue with the default topic 'transactions'. Being a Microservice we will deploy the data-generator on kubernetes.
- Stream Processing: As we require fast response times, we use Apache Flink as a Stream processor running the [FinancialTransactionJob](https://github.com/dcos/demos/tree/master/flink/1.10/flink-job/src/main/java/io/dcos).
- Storage: Here we diverge a bit from the typical SMACK stack setup and don't write the results into a Datastore such as Apache Cassandra. Instead we write the results again into a Kafka Stream (default: 'fraud'). Note, that Kafka also offers data persistence for all unprocessed events.
- Actor: In order to view the results we use again a small [Golang viewer](https://github.com/dcos/demos/blob/master/flink/1.11/actor/actor_viewer.go) which simply reads and displays the results from the output Kafka stream. Being a Microservice we will deploy the viewer on kubernetes.

## Prerequisites

Before you get started:

- Have KUDO installed on your cluster [ [Getting Started](https://kudo.dev/docs/getting-started/) ]
- Have the `zookeeper` Framework with `0.1.0` as FrameworkVersion installed 
    - Use the KUDO CLI with the following command:
        ```bash
        $ kubectl kudo install zookeeper --package-version=0.1.0
        framework.kudo.dev/v1alpha1/zookeeper created
        frameworkversion.kudo.dev/v1alpha1/zookeeper-0.1.0 created
        No Instance tied to this "zookeeper" version has been found. Do you want to create one? (Yes/no) no

        ```
        *Note: Don't forget to say "**no**" when prompted, we just want to install the Framework and FrameworkVersion objects but we don't want to instantiate an Instance object*
- Have the `kafka` Framework with `0.1.0` as FrameworkVersion installed 
    - Use the KUDO CLI with the following command:
        ```bash
        $ kubectl kudo install kafka --package-version=0.1.0
        framework.kudo.dev/v1alpha1/kafka created
        frameworkversion.kudo.dev/v1alpha1/kafka-0.1.0 created
        No Instance tied to this "kafka" version has been found. Do you want to create one? (Yes/no) no

        ```
        *Note: Don't forget to say "**no**" when prompted, we just want to install the Framework and FrameworkVersion objects but we don't want to instantiate an Instance object*
- Have the `flink` Framework with `0.2.0` as FrameworkVersion installed 
    - Get the KUDO Frameworks repository: `git clone git@github.com:kudobuilder/frameworks.git`
    - Change directory into the cloned repository: `cd kudo`
    - Install the Flink `0.2.0` objects straight out the repository:
        - `kubectl create -f repository/flink/0.2.0/flink-framework.yaml`
        - `kubectl create -f repository/flink/0.2.0/flink-frameworkversion.yaml`
        
Now you should have all required Frameworks installed.

## Getting Started

Install the `flink-financial-demo` from the main repository directory via:

`kubectl create -f repository/flink/docs/demo/financial-fraud/flink-demo.yaml`

To see if Flink is working properly run:

`kubectl proxy` and access in your web-browser: http://127.0.0.1:8001/api/v1/namespaces/default/services/demo-flink-jobmanager:ui/proxy/#/overview

Wait until Zookeeper, Kafka and Flink are healthy and running.
Once everything is up, start the job:

### Deploy Upload Plan

```bash
cat <<EOF | kubectl apply -f -
apiVersion: kudo.dev/v1alpha1
kind: PlanExecution
metadata:
  labels:
    framework-version: flink-financial-demo
    instance: demo-flink-submit-job
  name: flink-submit-job
  namespace: default
spec:
  instance:
    kind: Instance
    name: demo
    namespace: default
  planName: upload
EOF
```

To get the job output:

```bash
$ kubectl logs $(kubectl get pod -l planexecution=flink-submit-job -o jsonpath="{.items[0].metadata.name}")
DOWNLOAD_URL: https://downloads.mesosphere.com/dcos-demo/flink/flink-job-1.0.jar FILE: flink-job-1.0.jar JOBMANAGER: demo-flink-jobmanager
fetch http://dl-cdn.alpinelinux.org/alpine/v3.8/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.8/community/x86_64/APKINDEX.tar.gz
(1/7) Installing ca-certificates (20171114-r3)
(2/7) Installing nghttp2-libs (1.32.0-r0)
(3/7) Installing libssh2 (1.8.0-r3)
(4/7) Installing libcurl (7.61.1-r1)
(5/7) Installing curl (7.61.1-r1)
(6/7) Installing oniguruma (6.8.2-r0)
(7/7) Installing jq (1.6_rc1-r1)
Executing busybox-1.28.4-r2.trigger
Executing ca-certificates-20171114-r3.trigger
OK: 15 MiB in 24 packages
{"filename":"/tmp/flink-web-1324b551-a734-43fe-824b-396d7760647c/flink-web-upload/684b6919-9e66-4064-94d9-22641c9c2fb1_flink-job-1.0.jar","status":"success"}Thu Jan 24 04:59:15 UTC 2019
No uploaded jar detected
=====================
Thu Jan 24 04:59:20 UTC 2019
Found jar 684b6919-9e66-4064-94d9-22641c9c2fb1_flink-job-1.0.jar
RESPONSE: null
SUBMITTED JOB!
```

To get the fraud output from the actor:

```bash
kubectl logs $(kubectl get pod -l step=act -o jsonpath="{.items[0].metadata.name}")
```

Congratulations, you just installed a highly available Flink cluster that runs a financial fraud detection job!

### Clean the state

To successfully uninstall the demo follow those steps:

- Delete the demo yamls: `kubectl delete -f repository/flink/docs/demo/financial-fraud/flink-demo.yaml `
- Delete all PVCs:
    - For Kafka: `kubectl delete pvc -l instance=demo-kafka`
    - For Zookeeper: `kubectl delete pvc -l instance=demo-zk`